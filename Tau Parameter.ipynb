{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7630d40d-3d47-4e93-bdd4-50e96c560cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41f4d90-55c8-4548-94aa-f19bc6bb61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_excel('Fuhrer and Hock data.xlsx', index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cb338-ce00-450c-9c18-83734a004f68",
   "metadata": {},
   "source": [
    "2013 Allaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa71dce-ead9-40c9-9705-db08326fb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def step1_time_series_regression(df, market_col):\n",
    "    \"\"\"\n",
    "    Perform time-series regression of excess returns on excess market returns.\n",
    "    \"\"\"\n",
    "    market_returns = df[market_col].values.reshape(-1, 1)\n",
    "    betas = {}\n",
    "    intercepts = {}\n",
    "    for asset in df.columns:\n",
    "        if asset != market_col:\n",
    "            model = LinearRegression()\n",
    "            model.fit(market_returns, df[asset].values)\n",
    "            betas[asset] = model.coef_[0]\n",
    "            intercepts[asset] = model.intercept_\n",
    "    return betas, intercepts\n",
    "\n",
    "def step2_demeaning_and_residuals(df, betas, intercepts, market_col):\n",
    "    \"\"\"\n",
    "    Demean the residuals and regress on demeaned excess market returns.\n",
    "    \"\"\"\n",
    "    market_returns = df[market_col].values\n",
    "    residuals = df.drop(columns=[market_col]).copy()\n",
    "    for asset in residuals.columns:\n",
    "        residuals[asset] = df[asset] - (intercepts[asset] + betas[asset] * market_returns)\n",
    "    \n",
    "    demeaned_market = market_returns - market_returns.mean()\n",
    "    demeaned_residuals = residuals - residuals.mean()\n",
    "    return demeaned_market, demeaned_residuals.values\n",
    "\n",
    "def step3_cross_sectional_regression(demeaned_market, demeaned_residuals):\n",
    "    \"\"\"\n",
    "    Perform cross-sectional regression of average excess returns on coefficient estimates.\n",
    "    \"\"\"\n",
    "    avg_excess_returns = demeaned_residuals.mean(axis=0)\n",
    "    demeaned_market_mean = np.mean(demeaned_market).reshape(-1, 1)\n",
    "    demeaned_market_mean = np.full_like(avg_excess_returns, demeaned_market_mean)  # Ensure the correct shape\n",
    "    model = LinearRegression()\n",
    "    model.fit(demeaned_market_mean.reshape(-1, 1), avg_excess_returns)\n",
    "    return model.intercept_, model.coef_[0]\n",
    "\n",
    "def step4_quadratic_form(df, market_col, intercept, slope, demeaned_market, demeaned_residuals):\n",
    "    \"\"\"\n",
    "    Estimate tau using the quadratic form.\n",
    "    \"\"\"\n",
    "    T = len(df)\n",
    "    n = df.shape[1] - 1\n",
    "    avg_excess_returns = df.drop(columns=[market_col]).mean(axis=0)\n",
    "    residual_cov_matrix = np.cov(demeaned_residuals, rowvar=False)\n",
    "    diff = avg_excess_returns - slope * np.mean(demeaned_market)\n",
    "    tau = (T / n) * diff.T @ np.linalg.inv(residual_cov_matrix) @ diff\n",
    "    return tau\n",
    "\n",
    "def allaj_2013(df, market_col):\n",
    "    \"\"\"\n",
    "    Main function to estimate tau parameter based on Allaj 2013 method.\n",
    "    \"\"\"\n",
    "    betas, intercepts = step1_time_series_regression(df, market_col)\n",
    "    demeaned_market, demeaned_residuals = step2_demeaning_and_residuals(df, betas, intercepts, market_col)\n",
    "    intercept, slope = step3_cross_sectional_regression(demeaned_market, demeaned_residuals)\n",
    "    tau = step4_quadratic_form(df, market_col, intercept, slope, demeaned_market, demeaned_residuals)\n",
    "    return tau\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `all_data` is your pandas dataframe with excess daily returns\n",
    "# and \"MSCI Europe\" is the column name of the market reference.\n",
    "# tau_estimate = allaj_2013(all_data, \"MSCI Europe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d573cd9b-d364-4094-a85f-7b16fdf593ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSCI Austria': 1.3602289402647754,\n",
       " 'MSCI Belgium': 0.9580881449485984,\n",
       " 'MSCI Denmark': 0.8468063377032629,\n",
       " 'MSCI Finland': 1.0119400748984748,\n",
       " 'MSCI France': 1.1209306390642257,\n",
       " 'MSCI Germany': 1.1300653129699272,\n",
       " 'MSCI Ireland': 0.8971847510794795,\n",
       " 'MSCI Italy': 1.215845962550725,\n",
       " 'MSCI Netherlands': 1.0059292958268455,\n",
       " 'MSCI Norway': 1.0436601065675963,\n",
       " 'MSCI Portugal': 0.9711175493846661,\n",
       " 'MSCI Spain': 1.1374568916033192,\n",
       " 'MSCI Sweden': 1.044260115489641,\n",
       " 'MSCI Switzerland': 0.8206955028393137,\n",
       " 'MSCI UK': 0.9234870995248411}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1_time_series_regression(all_data, \"MSCI Europe\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3feea62c-29f0-4f3e-b67e-638d2d591c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2372.5034048523517"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allaj_2013_tau = allaj_2013(all_data, \"MSCI Europe\")\n",
    "allaj_2013_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15554a3-cd37-4b41-9156-a79defb9722f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55f6de-d490-4089-a5c9-5a8a58f2396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fuhrer and Hock - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d793dd-5f1c-441c-830c-8a076d821a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "all_data = pd.read_excel('Fuhrer and Hock data.xlsx', index_col='Date')\n",
    "\n",
    "# Step 1: Estimate the Error Covariance Matrix\n",
    "def step_1(all_data):\n",
    "    market_mean = all_data['MSCI Europe'].mean()\n",
    "    residuals = {}\n",
    "    \n",
    "    for column in all_data.columns:\n",
    "        if column != 'MSCI Europe':\n",
    "            asset_mean = all_data[column].mean()\n",
    "            adjusted_market_returns = all_data['MSCI Europe'] - market_mean\n",
    "            adjusted_asset_returns = all_data[column] - asset_mean\n",
    "            \n",
    "            model = LinearRegression().fit(adjusted_market_returns.values.reshape(-1, 1), adjusted_asset_returns.values.flatten())\n",
    "            predicted_returns = model.predict(adjusted_market_returns.values.reshape(-1, 1))\n",
    "            residuals[column] = adjusted_asset_returns - predicted_returns\n",
    "    \n",
    "    residuals_df = pd.DataFrame(residuals)\n",
    "    error_cov_matrix = residuals_df.cov()\n",
    "    return error_cov_matrix, residuals_df\n",
    "\n",
    "# Step 2: Stratification for Consistent Estimation\n",
    "def step_2(residuals_df, num_constituents):\n",
    "    T = residuals_df.shape[0]\n",
    "    pooled_var = residuals_df.var(ddof=1)\n",
    "    \n",
    "    demeaned_vars = []\n",
    "    for column in residuals_df.columns:\n",
    "        residuals = residuals_df[column]\n",
    "        time_indices = np.arange(T)\n",
    "        demeaned_model = LinearRegression().fit(time_indices.reshape(-1, 1), residuals.values)\n",
    "        demeaned_residuals = residuals - demeaned_model.predict(time_indices.reshape(-1, 1))\n",
    "        demeaned_var = np.var(demeaned_residuals, ddof=1)\n",
    "        demeaned_vars.append(demeaned_var)\n",
    "    \n",
    "    demeaned_var = np.array(demeaned_vars)\n",
    "    \n",
    "    # Adjust stratified estimates based on the number of constituents\n",
    "    stratified_estimates = (pooled_var - demeaned_var) / (T * np.array(num_constituents))\n",
    "    \n",
    "    return np.diag(stratified_estimates), num_constituents\n",
    "\n",
    "# Step 3: Obtain Beta and Other Parameters\n",
    "def step_3(all_data, error_cov_matrix):\n",
    "    market_mean = all_data['MSCI Europe'].mean()\n",
    "    market_returns = all_data['MSCI Europe'] - market_mean\n",
    "    asset_returns = all_data.drop(columns=['MSCI Europe'])\n",
    "\n",
    "    betas = {}\n",
    "    for column in asset_returns.columns:\n",
    "        asset_mean = all_data[column].mean()\n",
    "        adjusted_asset_returns = all_data[column] - asset_mean\n",
    "        \n",
    "        beta = np.linalg.lstsq(market_returns.values.reshape(-1, 1), adjusted_asset_returns.values.flatten(), rcond=None)[0]\n",
    "        betas[column] = beta[0]\n",
    "    \n",
    "    beta_vector = np.array(list(betas.values())).reshape(-1, 1)\n",
    "    sigma_m = np.var(market_returns, ddof=1)\n",
    "    sigma = beta_vector.dot(beta_vector.T) * sigma_m + error_cov_matrix\n",
    "    \n",
    "    return beta_vector, sigma_m, sigma\n",
    "\n",
    "# Step 4: Cross-Sectional Regression to Estimate Sigma_m\n",
    "def step_4(all_data, beta_vector):\n",
    "    market_mean = all_data['MSCI Europe'].mean()\n",
    "    market_returns = all_data['MSCI Europe'] - market_mean\n",
    "    \n",
    "    sigma_m_hat = np.var(market_returns, ddof=1)\n",
    "    \n",
    "    return sigma_m_hat\n",
    "\n",
    "# Step 5: Calculate Tau as a Vector\n",
    "def calculate_tau(sigma_m_hat, sigma_m, stratified_estimates, num_constituents):\n",
    "    tau_vector = (stratified_estimates.diagonal() * (sigma_m_hat / sigma_m)) / np.array(num_constituents)\n",
    "    return tau_vector\n",
    "\n",
    "# Provided list of number of constituents\n",
    "num_constituents = [5, 11, 17, 11, 68, 48, 5, 19, 15, 9, 4, 16, 34, 39, 83]\n",
    "\n",
    "# Step 1\n",
    "error_cov_matrix, residuals_df = step_1(all_data)\n",
    "\n",
    "# Step 2\n",
    "stratified_estimates, num_constituents = step_2(residuals_df, num_constituents)\n",
    "\n",
    "# Step 3\n",
    "beta_vector, sigma_m, sigma = step_3(all_data, error_cov_matrix)\n",
    "\n",
    "# Step 4\n",
    "sigma_m_hat = step_4(all_data, beta_vector)\n",
    "\n",
    "# Step 5\n",
    "tau_vector = calculate_tau(sigma_m_hat, sigma_m, stratified_estimates, num_constituents)\n",
    "\n",
    "# Creating Table 4\n",
    "asset_names = all_data.columns.drop('MSCI Europe')\n",
    "num_assets = len(asset_names)\n",
    "\n",
    "table_4 = pd.DataFrame({\n",
    "    'Asset': asset_names,\n",
    "    'Number of Constituents': num_constituents,\n",
    "    'Beta': beta_vector.flatten(),\n",
    "    'Sigma_m': [sigma_m] * num_assets,\n",
    "    'Sigma': [sigma.iloc[i, i] for i in range(num_assets)],\n",
    "    'Tau': tau_vector,\n",
    "    'Stratified Estimates': stratified_estimates.diagonal()\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(table_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10838bcc-fa9e-4ba7-b602-9c3ab38a4b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe6017-831e-4834-a99f-2361c31f5014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c38926-3cd9-4ac8-93ca-97cfd4baadf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddc97a-f2a2-4c4d-8fdc-0c00c5d604ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588fc91-a08f-4811-9d57-c5be899ad883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7d148-f6f5-4e38-915d-fcf9ffc8d819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088307d-f028-4b4b-a10d-bc4a7fda7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "error_cov_matrix, residuals_df = step_1(all_data)\n",
    "\n",
    "# Step 2\n",
    "stratified_estimates, n_assets = step_2(residuals_df)\n",
    "\n",
    "# Step 3\n",
    "beta_vector, sigma_m, sigma = step_3(all_data, error_cov_matrix)\n",
    "\n",
    "# Step 4\n",
    "sigma_m_hat = step_4(all_data, beta_vector)\n",
    "\n",
    "# Step 5: Calculate Tau as a Vector\n",
    "tau_vector = calculate_tau(sigma_m_hat, sigma_m, stratified_estimates, n_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f4957-a249-43ef-be28-77783e3b142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c5d44-3b8c-4d4c-9486-73d7783cc9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asset_names = all_data.columns.drop('MSCI Europe')\n",
    "\n",
    "# Ensure the lengths of all arrays are the same\n",
    "num_assets = len(asset_names)\n",
    "\n",
    "# Create a DataFrame for Table 4\n",
    "table_4 = pd.DataFrame({\n",
    "    'Asset': asset_names,\n",
    "    #'Beta': beta_vector.flatten(),\n",
    "    #'Sigma_m': [sigma_m] * num_assets,\n",
    "    #'Sigma': [sigma.iloc[i, i] for i in range(num_assets)],\n",
    "    #'Tau': tau_vector.flatten(),\n",
    "    'Stratified Estimates': [stratified_estimates[i, i] for i in range(num_assets)]\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(table_4)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "859296ee-0b93-49f1-a8c0-eb8090d9ba15",
   "metadata": {},
   "source": [
    "## Allaj 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae3c29-d549-459e-b85c-ecfc5183381e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
