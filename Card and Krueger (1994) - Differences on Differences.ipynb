{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is intended for a PhD subject of Econometric Methods in order to apply the Differences-in-Differences (DID) methodology.\n",
    "\n",
    "In their article entitled 'Employment Effects of Minimum and Subminimum Wages: Panel Data on State Minimum Wage Laws', Card and Krueger (1994) investigate how minimum wage legislation affects employment. On April 1, 1992, New Jersey (NJ) raised the state minimum wage from 4.25 USD to 5.05 USD, while the minimum wage in Pennsylvania (PA) stayed at 4.25 USD. Data about employment in fast-food restaurants in NJ and PA were collected in February 1992 and November 1992.\n",
    "\n",
    "Their analysis looks at both traditional minimum wages and subminimum wages paid to disabled workers or those with specific work conditions across several states using a thorough empirical approach that accounts for regional differences in industry-specific factors. We have applied this methodology to the same dataset from 1994.\n",
    "\n",
    "The authors analysed the full-time equivalent (FTE) employees by adding full-time employees with managers with half of the part-time workers. This was performed by using Jupiter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 399 entries, 46 to 428\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   CHAIN     399 non-null    int64  \n",
      " 1   CO_OWNED  399 non-null    int64  \n",
      " 2   STATE     399 non-null    int64  \n",
      " 3   SOUTHJ    399 non-null    int64  \n",
      " 4   CENTRALJ  399 non-null    int64  \n",
      " 5   NORTHJ    399 non-null    int64  \n",
      " 6   PA1       399 non-null    int64  \n",
      " 7   PA2       399 non-null    int64  \n",
      " 8   SHORE     399 non-null    int64  \n",
      " 9   NCALLS    399 non-null    int64  \n",
      " 10  EMPFT     399 non-null    float64\n",
      " 11  EMPPT     399 non-null    float64\n",
      " 12  NMGRS     399 non-null    float64\n",
      " 13  WAGE_ST   399 non-null    float64\n",
      " 14  INCTIME   399 non-null    float64\n",
      " 15  FIRSTINC  399 non-null    float64\n",
      " 16  BONUS     399 non-null    int64  \n",
      " 17  PCTAFF    399 non-null    float64\n",
      " 18  MEALS     399 non-null    int64  \n",
      " 19  OPEN      399 non-null    float64\n",
      " 20  HRSOPEN   399 non-null    float64\n",
      " 21  PSODA     399 non-null    float64\n",
      " 22  PFRY      399 non-null    float64\n",
      " 23  PENTREE   399 non-null    float64\n",
      " 24  NREGS     399 non-null    int64  \n",
      " 25  NREGS11   399 non-null    int64  \n",
      " 26  TYPE2     399 non-null    int64  \n",
      " 27  STATUS2   399 non-null    int64  \n",
      " 28  DATE2     399 non-null    int64  \n",
      " 29  NCALLS2   399 non-null    int64  \n",
      " 30  EMPFT2    399 non-null    float64\n",
      " 31  EMPPT2    399 non-null    float64\n",
      " 32  NMGRS2    399 non-null    float64\n",
      " 33  WAGE_ST2  399 non-null    float64\n",
      " 34  INCTIME2  399 non-null    float64\n",
      " 35  FIRSTIN2  399 non-null    float64\n",
      " 36  SPECIAL2  399 non-null    int64  \n",
      " 37  MEALS2    399 non-null    int64  \n",
      " 38  OPEN2R    399 non-null    float64\n",
      " 39  HRSOPEN2  399 non-null    float64\n",
      " 40  PSODA2    399 non-null    float64\n",
      " 41  PFRY2     399 non-null    float64\n",
      " 42  PENTREE2  399 non-null    float64\n",
      " 43  NREGS2    399 non-null    int64  \n",
      " 44  NREGS112  399 non-null    int64  \n",
      "dtypes: float64(23), int64(22)\n",
      "memory usage: 143.4 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table('Card and Krueger DataSet/public.dat',delim_whitespace=True, names=['SHEET','CHAIN','CO_OWNED','STATE','SOUTHJ','CENTRALJ','NORTHJ','PA1','PA2','SHORE','NCALLS','EMPFT','EMPPT','NMGRS','WAGE_ST','INCTIME','FIRSTINC','BONUS','PCTAFF','MEALS','OPEN','HRSOPEN','PSODA','PFRY','PENTREE','NREGS','NREGS11','TYPE2','STATUS2','DATE2','NCALLS2','EMPFT2','EMPPT2','NMGRS2','WAGE_ST2','INCTIME2','FIRSTIN2','SPECIAL2','MEALS2','OPEN2R','HRSOPEN2','PSODA2','PFRY2','PENTREE2','NREGS2','NREGS112'])\n",
    "df = df.set_index('SHEET')\n",
    "#We are looking for the observations where we had a response in the second round of interviews.\n",
    "df = df[df['STATUS2']==1]\n",
    "\n",
    "#We have a total of 399 observations as panel data\n",
    "df.replace('.',0, inplace=True)\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The authors assume a part time employee to count as 0.5\n",
    "df['Tot Emp Feb']=df['EMPPT']*.5 + df['EMPFT'] + df['NMGRS']                                            \n",
    "df['Tot Emp Nov']=df['EMPPT2']*.5 + df['EMPFT2'] + df['NMGRS2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tot Emp Feb</th>\n",
       "      <th>Tot Emp Nov</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.250000</td>\n",
       "      <td>20.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.344393</td>\n",
       "      <td>21.179907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tot Emp Feb  Tot Emp Nov\n",
       "STATE                          \n",
       "0        23.250000    20.958333\n",
       "1        20.344393    21.179907"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['STATE','Tot Emp Feb','Tot Emp Nov']].groupby('STATE').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean PA employment before: 23.25\n",
      "mean PA employment after: 20.96\n",
      "mean NJ employment before: 20.34\n",
      "mean NJ employment after: 21.18\n",
      "DID in mean employment is 3.13\n"
     ]
    }
   ],
   "source": [
    "# check by calculating the mean for each group directly\n",
    "# 0 PA control group, 1 NJ treatment group\n",
    "\n",
    "mean_emp_pa_before = df[['STATE','Tot Emp Feb','Tot Emp Nov']].groupby('STATE').mean().iloc[0, 0]\n",
    "mean_emp_pa_after = df[['STATE','Tot Emp Feb','Tot Emp Nov']].groupby('STATE').mean().iloc[0, 1]\n",
    "mean_emp_nj_before = df[['STATE','Tot Emp Feb','Tot Emp Nov']].groupby('STATE').mean().iloc[1, 0]\n",
    "mean_emp_nj_after = df[['STATE','Tot Emp Feb','Tot Emp Nov']].groupby('STATE').mean().iloc[1, 1]\n",
    "\n",
    "print(f'mean PA employment before: {mean_emp_pa_before:.2f}')\n",
    "print(f'mean PA employment after: {mean_emp_pa_after:.2f}')\n",
    "print(f'mean NJ employment before: {mean_emp_nj_before:.2f}')\n",
    "print(f'mean NJ employment after: {mean_emp_nj_after:.2f}')\n",
    "\n",
    "pa_diff = mean_emp_pa_after - mean_emp_pa_before\n",
    "nj_diff = mean_emp_nj_after - mean_emp_nj_before\n",
    "did = nj_diff - pa_diff\n",
    "\n",
    "print(f'DID in mean employment is {did:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contradicting economic theory, with the increase in the minimum wage in NJ, the results show an average increase in FTE. In PA, there was a decrease in the average FTE even though the minimum wage remained the same. However, the dataset is not equally split as there are more observations in NJ than in PA, which can lead to misleading results. Besides this, there is still the issue of assuming that employment in PA restaurants has similar behaviour to NJ restaurants."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same DID result can be obtained via regression, which allows adding control variables if needed:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 * g + \\beta_2 * t + \\beta_3 * (t * g) + \\varepsilon$\n",
    "\n",
    "- g is 0 for the control group and 1 for the treatment group\n",
    "- t is 0 for before and 1 for after\n",
    "\n",
    "we can insert the values of g and t using the table below and see that coefficient ($\\beta_3$) of the interaction of g and t is the value for DID：\n",
    "\n",
    "|              | Control Group (g=0) | Treatment Group (g=1)                   |                 |\n",
    "|--------------|---------------------|-----------------------------------------|-----------------|\n",
    "| Before (t=0) | $\\beta_0$           | $\\beta_0 + \\beta_1$                     |                 |\n",
    "| After (t=1)  | $\\beta_0 + \\beta_2$ | $\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3$ |                 |\n",
    "| Difference   | $\\beta_2$           | $\\beta_2 + \\beta_3$                     | $\\beta_3$ (DID) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PEDROR~1\\AppData\\Local\\Temp/ipykernel_13892/2962850996.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_before['t'] = 0\n",
      "C:\\Users\\PEDROR~1\\AppData\\Local\\Temp/ipykernel_13892/2962850996.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_after['t'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tot_Emp</th>\n",
       "      <th>g</th>\n",
       "      <th>t</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>23.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>20.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>20.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>798 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tot_Emp  g  t  gt\n",
       "0      40.50  0  0   0\n",
       "1      13.75  0  0   0\n",
       "2       8.50  0  0   0\n",
       "3      34.00  0  0   0\n",
       "4      24.00  0  0   0\n",
       "..       ... .. ..  ..\n",
       "394    23.75  1  1   1\n",
       "395    17.50  1  1   1\n",
       "396    20.50  1  1   1\n",
       "397    20.50  1  1   1\n",
       "398    25.00  1  1   1\n",
       "\n",
       "[798 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group g: 0 control group (PA), 1 treatment group (NJ)\n",
    "# t: 0 before treatment (min wage raise), 1 after treatment\n",
    "# gt: interaction of g * t\n",
    "\n",
    "# data before the treatment\n",
    "df_before = df[['Tot Emp Feb', 'STATE']]\n",
    "df_before['t'] = 0\n",
    "df_before.columns = ['Tot_Emp', 'g', 't']\n",
    "df_before = df_before.reset_index(drop=True)\n",
    "\n",
    "# data after the treatment\n",
    "df_after = df[['Tot Emp Nov', 'STATE']]\n",
    "df_after['t'] = 1\n",
    "df_after.columns = ['Tot_Emp', 'g', 't']\n",
    "df_after = df_after.reset_index(drop=True)\n",
    "# data for regression\n",
    "df_reg = pd.concat([df_before, df_after])\n",
    "\n",
    "# create the interaction \n",
    "df_reg['gt'] = df_reg.g * df_reg.t\n",
    "\n",
    "df_reg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this change we have a total of 798 observations (399 × 2). Then we estimated the model using Ordinary Least Squares (Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 1 lag and without small sample correction) and got the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Tot_Emp   R-squared:                       0.008\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     1.417\n",
      "Date:                Tue, 23 May 2023   Prob (F-statistic):              0.236\n",
      "Time:                        13:40:29   Log-Likelihood:                -2917.6\n",
      "No. Observations:                 798   AIC:                             5843.\n",
      "Df Residuals:                     794   BIC:                             5862.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HAC                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     23.2500      1.393     16.686      0.000      20.519      25.981\n",
      "g             -2.9056      1.488     -1.952      0.051      -5.823       0.012\n",
      "t             -2.2917      1.713     -1.338      0.181      -5.648       1.065\n",
      "gt             3.1272      1.866      1.676      0.094      -0.530       6.785\n",
      "==============================================================================\n",
      "Omnibus:                      221.565   Durbin-Watson:                   1.871\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              810.392\n",
      "Skew:                           1.281   Prob(JB):                    1.06e-176\n",
      "Kurtosis:                       7.220   Cond. No.                         11.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 1 lags and without small sample correction\n"
     ]
    }
   ],
   "source": [
    "# regression via statsmodels\n",
    "# result is not significant \n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "ols = ols('Tot_Emp ~ g + t + gt', data=df_reg).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "print(ols.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value in this example is not significant for a significance level of 5%. Therefore, we reject the null hypothesis, which means that the average total number of employees per restaurant increased after the minimal salary raise by 3.12 FTE. However, the result may be just due to random factors. Even if we consider a level of significance of 10%, we do not reject the null hypothesis and consider this coefficient equal to zero and not negative.\n",
    "\n",
    "The authors of the original paper did not use HAC robust standard errors. However, these results are consistent with them, as there is no evidence that the rise in NJ minimum wage reduced employment at fast-food restaurants in the state, as this coefficient is statistically higher than 0. Moreover, the authors found an increase in prices of fast-food meals in NJ relative to PA, suggesting that much of the burden of the minimum-wage rise was passed on to consumers. Furthermore, the employment of low-wage workers rose in NJ compared to PA, implying a shift of people from PA to NJ to look for better salaries.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
